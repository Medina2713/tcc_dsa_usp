# An√°lise de Performance: Script de Elenca√ß√£o

## üìä Situa√ß√£o Atual

**Tempo de processamento**: ~40 minutos por SKU  
**Gargalo principal**: Treinamento do modelo SARIMA via `auto_arima`

---

## üîç An√°lise Detalhada dos Gargalos

### 1. **Treinamento SARIMA (auto_arima) - ~95% do tempo**

#### Problema Identificado

O treinamento do modelo SARIMA √© o maior gargalo. No arquivo `previsoes/sarima_estoque.py` (linhas 143-167):

```python
modelo = auto_arima(
    serie,
    seasonal=True,
    m=30,
    stepwise=True,
    suppress_warnings=True,
    error_action='ignore',
    max_p=5,      # ‚ö†Ô∏è ALTO: testa 0,1,2,3,4,5
    max_d=2,      # ‚ö†Ô∏è ALTO: testa 0,1,2
    max_q=5,      # ‚ö†Ô∏è ALTO: testa 0,1,2,3,4,5
    max_P=2,      # ‚ö†Ô∏è ALTO: testa 0,1,2
    max_D=1,      # OK
    max_Q=2,      # ‚ö†Ô∏è ALTO: testa 0,1,2
    information_criterion='aic',
    trace=False,
    n_jobs=-1     # ‚ö†Ô∏è Pode n√£o estar funcionando corretamente
)
```

#### C√°lculo de Combina√ß√µes

Com os par√¢metros atuais:
- **N√£o-sazonal**: (5+1) √ó (2+1) √ó (5+1) = **108 combina√ß√µes base**
- **Sazonal**: (2+1) √ó (1+1) √ó (2+1) = **18 combina√ß√µes sazonais**
- **Total te√≥rico**: 108 √ó 18 = **1.944 combina√ß√µes poss√≠veis**

O `stepwise=True` reduz isso, mas ainda testa **centenas de combina√ß√µes** por SKU.

#### Impacto no Tempo

- Cada combina√ß√£o testada requer:
  1. Ajuste do modelo (MLE - Maximum Likelihood Estimation)
  2. C√°lculo de AIC/BIC
  3. Valida√ß√£o de estacionariedade
- **Tempo m√©dio por combina√ß√£o**: ~2-5 segundos
- **Total estimado**: 200-500 combina√ß√µes √ó 3s = **10-25 minutos por SKU**

---

### 2. **Carregamento Repetido de Dados CSV**

#### Problema Identificado

No arquivo `previsoes/teste_elencacao_3_skus.py`:

- **Linha 32**: `df_vendas = pd.read_csv(caminho_vendas, low_memory=False)` (fun√ß√£o `identificar_top_skus_movimentacao`)
- **Linha 63**: `df_vendas = pd.read_csv(caminho_vendas, low_memory=False)` (fun√ß√£o `calcular_metricas_vendas`)
- **Linha 103**: `df_vendas = pd.read_csv(caminho_vendas, low_memory=False)` (fun√ß√£o `calcular_venda_media_diaria`)
- **Linha 134**: `df_estoque = pd.read_csv(caminho_estoque, low_memory=False)` (fun√ß√£o `calcular_nivel_urgencia`)
- **Linha 175**: `df_estoque = pd.read_csv(caminho_estoque, low_memory=False)` (fun√ß√£o `gerar_previsoes_sarima`)

#### Impacto

- **Arquivo de vendas**: Carregado **3 vezes** (se ~32k linhas, ~50-100MB)
- **Arquivo de estoque**: Carregado **2 vezes** (se ~100k linhas, ~20-50MB)
- **Tempo total desperdi√ßado**: ~30-60 segundos por execu√ß√£o

---

### 3. **Processamento Sequencial (N√£o Paralelo)**

#### Problema Identificado

No arquivo `previsoes/teste_elencacao_3_skus.py` (linha 194):

```python
for sku in skus:  # ‚ö†Ô∏è Processa um SKU por vez
    # ... treina modelo SARIMA ...
```

Cada SKU √© processado **sequencialmente**, mesmo que o sistema tenha m√∫ltiplos cores dispon√≠veis.

#### Impacto

- **CPU ociosa**: Se h√° 8 cores, apenas 1 est√° sendo usado
- **Tempo total**: 3 SKUs √ó 40 min = **120 minutos** (poderia ser ~40-50 min com paraleliza√ß√£o)

---

### 4. **Prepara√ß√£o de S√©rie Temporal Repetida**

#### Problema Identificado

No arquivo `previsoes/sarima_estoque.py` (linha 44-81), a fun√ß√£o `preparar_serie_temporal`:

1. Filtra DataFrame completo por SKU
2. Converte datas
3. Ordena
4. Remove duplicatas
5. Cria √≠ndice temporal
6. Preenche frequ√™ncia
7. Remove NaN

Isso √© feito **a cada chamada**, mesmo que os dados n√£o tenham mudado.

#### Impacto

- **Tempo por prepara√ß√£o**: ~1-3 segundos
- **Repetido**: 3 vezes por SKU (prepara√ß√£o, treino, previs√£o)
- **Total desperdi√ßado**: ~3-9 segundos por SKU

---

### 5. **Falta de Cache de Modelos Treinados**

#### Problema Identificado

O sistema n√£o salva modelos treinados. Se o mesmo SKU for processado novamente, o modelo √© **retreinado do zero**.

#### Impacto

- **Retreinamento desnecess√°rio**: Se processar os mesmos SKUs, perde 40 min por SKU novamente
- **Sem persist√™ncia**: Modelos n√£o podem ser reutilizados

---

### 6. **Paraleliza√ß√£o do auto_arima N√£o Eficiente**

#### Problema Identificado

O par√¢metro `n_jobs=-1` no `auto_arima` **n√£o paraleliza a busca de par√¢metros**. Ele paraleliza apenas:
- Testes de estacionariedade (ADF)
- Algumas opera√ß√µes internas

A **busca stepwise √© sequencial** por design.

#### Impacto

- **CPU subutilizada**: Mesmo com `n_jobs=-1`, apenas 1-2 cores s√£o usadas efetivamente

---

## üöÄ Oportunidades de Otimiza√ß√£o

### **Categoria 1: Otimiza√ß√µes de C√≥digo (Sem GPU)**

#### 1.1. Reduzir Par√¢metros do auto_arima ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Impacto**: **Alto** (redu√ß√£o de 60-80% no tempo)

**Mudan√ßa proposta**:
```python
# ATUAL (1.944 combina√ß√µes te√≥ricas)
max_p=5, max_d=2, max_q=5, max_P=2, max_D=1, max_Q=2

# OTIMIZADO (108 combina√ß√µes te√≥ricas)
max_p=3, max_d=1, max_q=3, max_P=1, max_D=1, max_Q=1
```

**Justificativa**:
- Modelos SARIMA raramente precisam de ordens > 3
- A maioria dos modelos reais usa (1,1,1) ou (2,1,2)
- Redu√ß√£o de **18x menos combina√ß√µes** a testar

**Tempo estimado**: 40 min ‚Üí **8-12 min por SKU**

---

#### 1.2. Cache de Modelos Treinados ‚≠ê‚≠ê‚≠ê‚≠ê

**Impacto**: **Muito Alto** (para reprocessamento)

**Implementa√ß√£o**:
- Salvar modelos treinados em `pickle` ou `joblib`
- Verificar se modelo j√° existe antes de treinar
- Reutilizar modelo se dados n√£o mudaram

**Tempo estimado**: 40 min ‚Üí **0 min** (se cache existe)

---

#### 1.3. Carregamento √önico de Dados ‚≠ê‚≠ê‚≠ê

**Impacto**: **M√©dio** (redu√ß√£o de 30-60 segundos)

**Mudan√ßa proposta**:
- Carregar dados uma vez no in√≠cio
- Passar DataFrames como par√¢metros entre fun√ß√µes
- Evitar m√∫ltiplos `pd.read_csv()`

**Tempo estimado**: Economia de **30-60 segundos** por execu√ß√£o

---

#### 1.4. Prepara√ß√£o de S√©rie Temporal em Cache ‚≠ê‚≠ê‚≠ê

**Impacto**: **M√©dio** (redu√ß√£o de 3-9 segundos por SKU)

**Mudan√ßa proposta**:
- Preparar todas as s√©ries temporais uma vez
- Armazenar em dicion√°rio `{sku: serie}`
- Reutilizar s√©ries preparadas

**Tempo estimado**: Economia de **3-9 segundos por SKU**

---

#### 1.5. Processamento Paralelo de SKUs ‚≠ê‚≠ê‚≠ê‚≠ê

**Impacto**: **Alto** (redu√ß√£o proporcional ao n√∫mero de cores)

**Implementa√ß√£o**:
- Usar `multiprocessing.Pool` ou `concurrent.futures.ProcessPoolExecutor`
- Processar m√∫ltiplos SKUs simultaneamente
- Limitar n√∫mero de processos ao n√∫mero de cores

**Tempo estimado**: 
- 3 SKUs sequenciais: 120 min
- 3 SKUs paralelos (4 cores): **~40-50 min**

---

#### 1.6. Usar BIC em vez de AIC ‚≠ê‚≠ê

**Impacto**: **Baixo-M√©dio** (pode reduzir complexidade dos modelos)

**Mudan√ßa proposta**:
```python
information_criterion='bic'  # Penaliza mais modelos complexos
```

**Justificativa**:
- BIC tende a escolher modelos mais simples
- Modelos mais simples = menos tempo de treino
- Pode reduzir 10-20% do tempo

---

#### 1.7. Limitar Tamanho da S√©rie Temporal ‚≠ê‚≠ê

**Impacto**: **M√©dio** (redu√ß√£o de 20-30% no tempo)

**Mudan√ßa proposta**:
- Usar apenas √∫ltimos N dias (ex: 365 dias)
- Reduz tamanho da s√©rie = menos c√°lculos

**Tempo estimado**: Redu√ß√£o de **20-30%** no tempo de treino

---

### **Categoria 2: Otimiza√ß√µes com GPU**

#### 2.1. GPU para auto_arima? ‚ùå **N√ÉO RECOMENDADO**

**An√°lise**:
- `pmdarima` (auto_arima) **n√£o suporta GPU**
- √â baseado em `statsmodels` e `scipy`, que s√£o CPU-only
- A busca de par√¢metros √© sequencial por design

**Conclus√£o**: **N√£o √© vi√°vel usar GPU para auto_arima diretamente**

---

#### 2.2. Alternativas com GPU ‚≠ê‚≠ê‚≠ê

**Op√ß√£o A: Usar TensorFlow/PyTorch para Previs√£o**

**Implementa√ß√£o**:
- Treinar modelo LSTM/GRU na GPU
- Usar apenas para previs√£o (n√£o para busca de par√¢metros)
- Manter SARIMA para valida√ß√£o

**Vantagens**:
- Treino LSTM na GPU: **10-50x mais r√°pido** que CPU
- Pode processar m√∫ltiplos SKUs em batch

**Desvantagens**:
- Requer reimplementa√ß√£o significativa
- LSTM pode n√£o capturar sazonalidade t√£o bem quanto SARIMA
- Requer mais dados para treinar

**Tempo estimado**: 40 min ‚Üí **2-5 min por SKU** (apenas treino LSTM)

---

**Op√ß√£o B: Usar RAPIDS cuDF para Processamento de Dados**

**Implementa√ß√£o**:
- Substituir `pandas` por `cudf` (GPU DataFrame)
- Processar agrega√ß√µes e merges na GPU
- Manter auto_arima na CPU

**Vantagens**:
- Agrega√ß√µes e merges **10-100x mais r√°pidos** na GPU
- Carregamento de dados mais r√°pido

**Desvantagens**:
- Requer GPU NVIDIA com CUDA
- N√£o acelera o auto_arima (principal gargalo)
- Ganho limitado (~5-10% do tempo total)

**Tempo estimado**: 40 min ‚Üí **38-39 min por SKU** (ganho m√≠nimo)

---

**Op√ß√£o C: Usar Dask para Paraleliza√ß√£o Distribu√≠da**

**Implementa√ß√£o**:
- Usar `dask` para processar m√∫ltiplos SKUs em paralelo
- Pode usar GPU workers se dispon√≠vel
- Distribuir carga entre m√∫ltiplos processos/GPUs

**Vantagens**:
- Escala horizontalmente (m√∫ltiplas GPUs/m√°quinas)
- Processa muitos SKUs simultaneamente

**Desvantagens**:
- Complexidade de setup
- Overhead de comunica√ß√£o
- Ainda n√£o acelera auto_arima individual

**Tempo estimado**: 100 SKUs ‚Üí **~40-50 min total** (vs 66 horas sequencial)

---

## üìà Compara√ß√£o de Estrat√©gias

### **Estrat√©gia 1: Otimiza√ß√µes Simples (Sem GPU)**

| Otimiza√ß√£o | Redu√ß√£o de Tempo | Complexidade | Prioridade |
|------------|------------------|--------------|------------|
| Reduzir par√¢metros auto_arima | 60-80% | Baixa | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Cache de modelos | 100% (reprocessamento) | M√©dia | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Carregamento √∫nico de dados | 1-2% | Baixa | ‚≠ê‚≠ê‚≠ê |
| Prepara√ß√£o de s√©rie em cache | 2-5% | Baixa | ‚≠ê‚≠ê‚≠ê |
| Processamento paralelo | 50-75% (m√∫ltiplos SKUs) | M√©dia | ‚≠ê‚≠ê‚≠ê‚≠ê |

**Tempo estimado final**: 40 min ‚Üí **5-8 min por SKU** (primeira execu√ß√£o)  
**Tempo estimado final**: 40 min ‚Üí **0-1 min por SKU** (com cache)

---

### **Estrat√©gia 2: Otimiza√ß√µes + GPU (LSTM)**

| Componente | Tempo Atual | Tempo com GPU | Ganho |
|------------|-------------|---------------|-------|
| Treino SARIMA | 40 min | 40 min | 0% |
| Treino LSTM | N/A | 2-5 min | - |
| Previs√£o | 1 min | 0.1 min | 90% |

**Tempo estimado final**: 40 min ‚Üí **2-5 min por SKU** (LSTM)  
**Nota**: Requer valida√ß√£o de que LSTM tem qualidade similar ao SARIMA

---

### **Estrat√©gia 3: H√≠brida (Otimiza√ß√µes + Paraleliza√ß√£o)**

| Componente | Tempo Atual | Tempo Otimizado | Ganho |
|------------|-------------|------------------|-------|
| 1 SKU sequencial | 40 min | 8 min | 80% |
| 3 SKUs sequenciais | 120 min | 24 min | 80% |
| 3 SKUs paralelos (4 cores) | 120 min | 8-12 min | 90-93% |

**Tempo estimado final**: **8-12 min para 3 SKUs** (primeira execu√ß√£o)

---

## üéØ Recomenda√ß√µes Priorit√°rias

### **Prioridade 1: Implementar Imediatamente** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

1. **Reduzir par√¢metros do auto_arima**
   - Mudan√ßa: `max_p=3, max_d=1, max_q=3, max_P=1, max_D=1, max_Q=1`
   - Impacto: **60-80% de redu√ß√£o** no tempo
   - Esfor√ßo: **5 minutos** (alterar 1 linha)

2. **Cache de modelos treinados**
   - Impacto: **100% de redu√ß√£o** em reprocessamento
   - Esfor√ßo: **30-60 minutos** (implementar sistema de cache)

---

### **Prioridade 2: Implementar em Seguida** ‚≠ê‚≠ê‚≠ê‚≠ê

3. **Processamento paralelo de SKUs**
   - Impacto: **50-75% de redu√ß√£o** para m√∫ltiplos SKUs
   - Esfor√ßo: **1-2 horas** (implementar multiprocessing)

4. **Carregamento √∫nico de dados**
   - Impacto: **1-2% de redu√ß√£o** + c√≥digo mais limpo
   - Esfor√ßo: **30 minutos** (refatorar fun√ß√µes)

---

### **Prioridade 3: Considerar no Futuro** ‚≠ê‚≠ê‚≠ê

5. **Prepara√ß√£o de s√©rie em cache**
   - Impacto: **2-5% de redu√ß√£o**
   - Esfor√ßo: **30 minutos**

6. **Limitar tamanho da s√©rie temporal**
   - Impacto: **20-30% de redu√ß√£o**
   - Esfor√ßo: **15 minutos**

---

### **Prioridade 4: Avaliar Alternativas** ‚≠ê‚≠ê

7. **LSTM com GPU** (se qualidade for aceit√°vel)
   - Impacto: **80-90% de redu√ß√£o** (mas requer valida√ß√£o)
   - Esfor√ßo: **1-2 semanas** (reimplementa√ß√£o significativa)

8. **RAPIDS cuDF** (se GPU dispon√≠vel)
   - Impacto: **5-10% de redu√ß√£o** (ganho limitado)
   - Esfor√ßo: **2-4 horas**

---

## üìä Estimativa de Ganho Total

### **Cen√°rio Conservador (Apenas Otimiza√ß√µes Simples)**

| Otimiza√ß√£o | Ganho Individual | Ganho Acumulado |
|------------|-------------------|-----------------|
| Baseline | 40 min/SKU | 40 min/SKU |
| Reduzir par√¢metros | -70% | 12 min/SKU |
| Cache de modelos | -100% (reprocessamento) | 0 min/SKU |
| Carregamento √∫nico | -1% | 11.9 min/SKU |
| Prepara√ß√£o em cache | -3% | 11.5 min/SKU |
| **TOTAL** | | **~11-12 min/SKU** (primeira vez) |

**Ganho total**: **70-72% de redu√ß√£o**

---

### **Cen√°rio Otimista (Otimiza√ß√µes + Paraleliza√ß√£o)**

| Otimiza√ß√£o | Ganho Individual | Ganho Acumulado |
|------------|-------------------|-----------------|
| Baseline | 40 min/SKU | 40 min/SKU |
| Reduzir par√¢metros | -70% | 12 min/SKU |
| Processamento paralelo (4 cores) | -75% (3 SKUs) | 3 min/SKU |
| Cache de modelos | -100% (reprocessamento) | 0 min/SKU |
| **TOTAL** | | **~3-4 min/SKU** (primeira vez, 3 SKUs) |

**Ganho total**: **90-92% de redu√ß√£o**

---

## üîß Detalhamento T√©cnico das Otimiza√ß√µes

### **1. Reduzir Par√¢metros do auto_arima**

**Arquivo**: `previsoes/sarima_estoque.py` (linha 143-167)

**Mudan√ßa**:
```python
# ANTES
max_p=5, max_d=2, max_q=5, max_P=2, max_D=1, max_Q=2

# DEPOIS
max_p=3, max_d=1, max_q=3, max_P=1, max_D=1, max_Q=1
```

**Justificativa Estat√≠stica**:
- Modelos ARIMA raramente precisam de ordens > 3
- A maioria dos modelos reais usa (1,1,1) ou (2,1,2)
- Sazonalidade mensal (m=30) raramente precisa de P, D, Q > 1

**Risco**: Baixo (pode perder modelos muito complexos, mas improv√°vel)

---

### **2. Cache de Modelos**

**Implementa√ß√£o proposta**:
```python
import pickle
from pathlib import Path

def carregar_modelo_cache(sku, cache_dir="cache_modelos"):
    cache_path = Path(cache_dir) / f"modelo_{sku}.pkl"
    if cache_path.exists():
        with open(cache_path, 'rb') as f:
            return pickle.load(f)
    return None

def salvar_modelo_cache(sku, modelo, cache_dir="cache_modelos"):
    Path(cache_dir).mkdir(exist_ok=True)
    cache_path = Path(cache_dir) / f"modelo_{sku}.pkl"
    with open(cache_path, 'wb') as f:
        pickle.dump(modelo, f)
```

**Valida√ß√£o de cache**:
- Verificar hash dos dados de entrada
- Se dados mudaram, retreinar modelo
- Se dados n√£o mudaram, reutilizar modelo

---

### **3. Processamento Paralelo**

**Implementa√ß√£o proposta**:
```python
from concurrent.futures import ProcessPoolExecutor
from multiprocessing import cpu_count

def processar_skus_paralelo(skus, df_estoque, n_workers=None):
    if n_workers is None:
        n_workers = min(len(skus), cpu_count())
    
    with ProcessPoolExecutor(max_workers=n_workers) as executor:
        futures = {
            executor.submit(processar_sku, sku, df_estoque): sku 
            for sku in skus
        }
        
        resultados = {}
        for future in futures:
            sku = futures[future]
            try:
                resultados[sku] = future.result()
            except Exception as e:
                print(f"Erro ao processar {sku}: {e}")
    
    return resultados
```

**Considera√ß√µes**:
- Cada processo precisa de c√≥pia dos dados
- Overhead de comunica√ß√£o entre processos
- Ideal para 4-8 SKUs simult√¢neos

---

### **4. Carregamento √önico de Dados**

**Refatora√ß√£o proposta**:
```python
def gerar_elencacao_completa():
    # Carregar dados UMA VEZ
    df_vendas = pd.read_csv("DB/venda_produtos_atual.csv", low_memory=False)
    df_estoque = pd.read_csv("DB/historico_estoque_atual.csv", low_memory=False)
    
    # Preparar dados
    df_vendas = preparar_dados_vendas(df_vendas)
    df_estoque = preparar_dados_estoque(df_estoque)
    
    # Passar DataFrames para fun√ß√µes
    top_skus = identificar_top_skus_movimentacao(df_vendas)
    metricas = calcular_metricas_vendas(df_vendas, top_skus)
    previsoes = gerar_previsoes_sarima(df_estoque, top_skus)
    
    # ...
```

---

## ‚ö†Ô∏è Riscos e Considera√ß√µes

### **Risco 1: Redu√ß√£o de Par√¢metros Pode Piorar Qualidade**

**Mitiga√ß√£o**:
- Validar modelos otimizados vs. modelos completos
- Comparar m√©tricas (MAE, RMSE, MAPE)
- Se qualidade degradar > 5%, ajustar par√¢metros incrementalmente

---

### **Risco 2: Cache de Modelos Pode Ficar Desatualizado**

**Mitiga√ß√£o**:
- Implementar sistema de versionamento de dados
- Invalidar cache quando dados mudarem
- Adicionar timestamp aos arquivos de cache

---

### **Risco 3: Paraleliza√ß√£o Pode Consumir Muita Mem√≥ria**

**Mitiga√ß√£o**:
- Limitar n√∫mero de workers ao n√∫mero de cores
- Processar em batches se muitos SKUs
- Monitorar uso de mem√≥ria

---

## üìù Resumo Executivo

### **Problema Principal**
- Treinamento SARIMA via `auto_arima` consome ~95% do tempo
- Par√¢metros altos (max_p=5, max_q=5) testam muitas combina√ß√µes
- Processamento sequencial n√£o aproveita m√∫ltiplos cores

### **Solu√ß√£o Recomendada (Imediata)**
1. **Reduzir par√¢metros do auto_arima**: `max_p=3, max_q=3, max_P=1, max_Q=1`
   - Ganho: **60-80% de redu√ß√£o** no tempo
   - Esfor√ßo: **5 minutos**

2. **Implementar cache de modelos**
   - Ganho: **100% de redu√ß√£o** em reprocessamento
   - Esfor√ßo: **30-60 minutos**

3. **Processamento paralelo de SKUs**
   - Ganho: **50-75% de redu√ß√£o** para m√∫ltiplos SKUs
   - Esfor√ßo: **1-2 horas**

### **Resultado Esperado**
- **Primeira execu√ß√£o**: 40 min ‚Üí **8-12 min por SKU**
- **Reprocessamento**: 40 min ‚Üí **0-1 min por SKU** (com cache)
- **3 SKUs paralelos**: 120 min ‚Üí **8-12 min total**

### **Sobre GPU**
- **auto_arima n√£o suporta GPU** (baseado em statsmodels/scipy)
- **Alternativa LSTM na GPU**: Vi√°vel, mas requer reimplementa√ß√£o
- **RAPIDS cuDF**: Ganho limitado (~5-10%) pois n√£o acelera auto_arima

### **Conclus√£o**
**Melhor estrat√©gia**: Otimiza√ß√µes de c√≥digo (sem GPU) podem reduzir tempo em **70-90%** com esfor√ßo baixo-m√©dio. GPU s√≥ seria √∫til se migrar para LSTM, o que requer valida√ß√£o de qualidade.

---

**Data da An√°lise**: 2024  
**Vers√£o**: 1.0

